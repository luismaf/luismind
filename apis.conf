# ═══════════════════════════════════════════════════════════════════════════════
# CONFIGURACIÓN DE APIs - LUISMIND
# ═══════════════════════════════════════════════════════════════════════════════
#
# Cada [seccion] define una API. El nombre de la sección es el identificador.
#
# PARÁMETROS DE RATE LIMITING:
#   cooldown_time    = Segundos de espera base después de un error (0 para locales)
#   max_cooldown     = Máximo cooldown después de backoff exponencial
#   cooldown_multiplier = Factor de incremento (1.5 = +50% cada error)
#   request_interval = Segundos entre requests exitosos
#
# ═══════════════════════════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════════════════════════
# APIs LOCALES - Sin cooldown, reintentos inmediatos
# ═══════════════════════════════════════════════════════════════════════════════

[ollama]
type = local
host = 127.0.0.1
port = 11434
models_command = ollama list
prefix = ollama
aider_model_prefix = ollama_chat/
default_context = 32768
cooldown_time = 0
enabled = true

[oobabooga]
type = local
host = 127.0.0.1
port = 5000
models_endpoint = /v1/models
prefix = ooba
aider_model_prefix = openai/
aider_api_base = http://127.0.0.1:5000/v1
aider_api_key = sk-dummy
default_context = 131072
cooldown_time = 0
enabled = true

[llama-cpp]
type = local
host = 127.0.0.1
port = 8080
models_endpoint = /v1/models
prefix = llama
aider_model_prefix = openai/
aider_api_base = http://127.0.0.1:8080/v1
aider_api_key = sk-dummy
default_context = 262144
cooldown_time = 0
enabled = true

[vllm]
type = local
host = 127.0.0.1
port = 8000
models_endpoint = /v1/models
prefix = vllm
aider_model_prefix = openai/
aider_api_base = http://127.0.0.1:8000/v1
aider_api_key = sk-dummy
default_context = 131072
cooldown_time = 0
enabled = false

# ═══════════════════════════════════════════════════════════════════════════════
# APIs CLOUD - Con cooldown y rotación de keys
# ═══════════════════════════════════════════════════════════════════════════════

[gemini]
type = cloud
env_key = GEMINI_API_KEY
models_url = https://generativelanguage.googleapis.com/v1beta/models
auth_type = query
auth_param = key
prefix = gemini
aider_model_prefix = gemini/
aider_env = GEMINI_API_KEY
default_context = 1000000
cooldown_time = 30
max_cooldown = 300
cooldown_multiplier = 1.5
request_interval = 1
enabled = true

[groq]
type = cloud
env_key = GROQ_API_KEY
models_url = https://api.groq.com/openai/v1/models
auth_type = bearer
prefix = groq
aider_model_prefix = groq/
aider_env = GROQ_API_KEY
default_context = 131072
cooldown_time = 30
max_cooldown = 120
cooldown_multiplier = 2.0
request_interval = 1
enabled = true

[deepseek]
type = cloud
env_key = DEEPSEEK_API_KEY
models_url = https://api.deepseek.com/v1/models
auth_type = bearer
prefix = deepseek
aider_model_prefix = deepseek/
aider_env = DEEPSEEK_API_KEY
default_context = 65536
cooldown_time = 60
max_cooldown = 300
cooldown_multiplier = 1.5
enabled = true

[openrouter]
type = cloud
env_key = OPENROUTER_API_KEY
models_url = https://openrouter.ai/api/v1/models
auth_type = bearer
prefix = openrouter
aider_model_prefix = openrouter/
aider_env = OPENROUTER_API_KEY
default_context = 131072
cooldown_time = 10
max_cooldown = 60
cooldown_multiplier = 1.5
enabled = true

[together]
type = cloud
env_key = TOGETHER_API_KEY
models_url = https://api.together.xyz/v1/models
auth_type = bearer
prefix = together
aider_model_prefix = together_ai/
aider_env = TOGETHER_API_KEY
default_context = 131072
cooldown_time = 30
max_cooldown = 180
cooldown_multiplier = 1.5
enabled = true

[fireworks]
type = cloud
env_key = FIREWORKS_API_KEY
models_url = https://api.fireworks.ai/inference/v1/models
auth_type = bearer
prefix = fireworks
aider_model_prefix = fireworks_ai/
aider_env = FIREWORKS_API_KEY
default_context = 131072
cooldown_time = 30
max_cooldown = 180
cooldown_multiplier = 1.5
enabled = true

[anthropic]
type = cloud
env_key = ANTHROPIC_API_KEY
models_url = https://api.anthropic.com/v1/models
auth_type = x-api-key
prefix = claude
aider_model_prefix = anthropic/
aider_env = ANTHROPIC_API_KEY
default_context = 200000
cooldown_time = 60
max_cooldown = 300
cooldown_multiplier = 2.0
enabled = true

[openai]
type = cloud
env_key = OPENAI_API_KEY
models_url = https://api.openai.com/v1/models
auth_type = bearer
prefix = openai
aider_model_prefix = openai/
aider_env = OPENAI_API_KEY
default_context = 128000
cooldown_time = 60
max_cooldown = 300
cooldown_multiplier = 2.0
enabled = true

[mistral]
type = cloud
env_key = MISTRAL_API_KEY
models_url = https://api.mistral.ai/v1/models
auth_type = bearer
prefix = mistral
aider_model_prefix = mistral/
aider_env = MISTRAL_API_KEY
default_context = 32768
cooldown_time = 30
max_cooldown = 180
cooldown_multiplier = 1.5
enabled = true

[cohere]
type = cloud
env_key = COHERE_API_KEY
models_url = https://api.cohere.ai/v1/models
auth_type = bearer
prefix = cohere
aider_model_prefix = cohere_chat/
aider_env = COHERE_API_KEY
default_context = 128000
cooldown_time = 30
max_cooldown = 180
cooldown_multiplier = 1.5
enabled = true

[cerebras]
type = cloud
env_key = CEREBRAS_API_KEY
models_url = https://api.cerebras.ai/v1/models
auth_type = bearer
prefix = cerebras
aider_model_prefix = cerebras/
aider_env = CEREBRAS_API_KEY
default_context = 8192
cooldown_time = 30
max_cooldown = 120
cooldown_multiplier = 1.5
enabled = true

[sambanova]
type = cloud
env_key = SAMBANOVA_API_KEY
models_url = https://api.sambanova.ai/v1/models
auth_type = bearer
prefix = sambanova
aider_model_prefix = sambanova/
aider_env = SAMBANOVA_API_KEY
default_context = 8192
cooldown_time = 30
max_cooldown = 120
cooldown_multiplier = 1.5
enabled = true

[chutes]
type = cloud
env_key = CHUTES_API_KEY
models_url = https://api.chutes.ai/v1/models
auth_type = bearer
prefix = chutes
aider_model_prefix = openai/
aider_env = CHUTES_API_KEY
default_context = 131072
cooldown_time = 30
max_cooldown = 180
cooldown_multiplier = 1.5
enabled = true
